{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding numbers of files in the training set with their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files 0\n",
      "number of files 72\n",
      "number of files 185\n",
      "number of files 252\n",
      "number of files 16\n",
      "number of files 214\n",
      "number of files 188\n",
      "number of files 196\n",
      "number of files 166\n",
      "number of files 164\n",
      "number of files 239\n",
      "number of files 168\n",
      "number of files 195\n",
      "number of files 187\n",
      "number of files 158\n",
      "number of files 132\n",
      "number of files 82\n",
      "number of files 118\n",
      "number of files 14\n",
      "number of files 56\n",
      "number of files 218\n",
      "number of files 182\n",
      "number of files 187\n",
      "number of files 188\n",
      "number of files 196\n",
      "number of files 54\n",
      "number of files 200\n",
      "number of files 232\n",
      "number of files 134\n",
      "number of files 102\n",
      "number of files 140\n",
      "number of files 180\n",
      "number of files 162\n",
      "number of files 172\n",
      "number of files 152\n",
      "number of files 160\n",
      "number of files 185\n",
      "number of files 138\n",
      "number of files 116\n",
      "number of files 197\n",
      "number of files 202\n",
      "number of files 202\n",
      "number of files 197\n",
      "number of files 196\n",
      "number of files 174\n",
      "number of files 178\n",
      "number of files 90\n",
      "number of files 114\n",
      "number of files 100\n",
      "number of files 122\n",
      "number of files 206\n",
      "number of files 183\n",
      "number of files 110\n",
      "number of files 150\n",
      "number of files 186\n",
      "number of files 70\n",
      "number of files 52\n",
      "number of files 42\n",
      "number of files 156\n",
      "number of files 142\n",
      "number of files 68\n",
      "number of files 88\n",
      "number of files 136\n",
      "number of files 98\n",
      "number of files 80\n",
      "number of files 66\n",
      "number of files 40\n",
      "number of files 130\n",
      "number of files 38\n",
      "number of files 128\n",
      "number of files 50\n",
      "number of files 36\n",
      "number of files 34\n",
      "number of files 86\n",
      "number of files 32\n",
      "number of files 30\n",
      "number of files 64\n",
      "number of files 78\n",
      "number of files 84\n",
      "number of files 148\n",
      "number of files 112\n",
      "number of files 76\n",
      "number of files 28\n",
      "number of files 26\n",
      "number of files 62\n",
      "number of files 60\n",
      "number of files 24\n",
      "number of files 184\n",
      "number of files 144\n",
      "number of files 218\n",
      "number of files 48\n",
      "number of files 202\n",
      "number of files 46\n",
      "number of files 108\n",
      "number of files 58\n",
      "number of files 126\n",
      "number of files 106\n",
      "number of files 154\n",
      "number of files 22\n",
      "number of files 170\n",
      "number of files 192\n",
      "number of files 20\n",
      "number of files 209\n",
      "number of files 200\n",
      "number of files 210\n",
      "number of files 195\n",
      "number of files 213\n",
      "number of files 218\n",
      "number of files 219\n",
      "number of files 196\n",
      "number of files 120\n",
      "number of files 74\n",
      "number of files 176\n",
      "number of files 96\n",
      "number of files 44\n",
      "number of files 94\n",
      "number of files 124\n",
      "number of files 92\n",
      "number of files 104\n",
      "number of files 18\n",
      "number of files 146\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "APP_FOLDER = r\"newimages\"\n",
    "\n",
    "totalFiles = 0\n",
    "totalDir = 0\n",
    "x=0\n",
    "y=[]\n",
    "for base, dirs, files in os.walk(APP_FOLDER):\n",
    "    if (x==0):\n",
    "        z=dirs\n",
    "    totalFiles = 0\n",
    "    for Files in files:\n",
    "        totalFiles += 1\n",
    "    Files=files\n",
    "    print('number of files',totalFiles)\n",
    "    if (x>0):\n",
    "        y.append(totalFiles)\n",
    "    x=x+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making a dictionary of training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n02085620-Chihuahua': 72,\n",
       " 'n02085782-Japanese_spaniel': 185,\n",
       " 'n02085936-Maltese_dog': 252,\n",
       " 'n02086079-Pekinese': 16,\n",
       " 'n02086240-Shih-Tzu': 214,\n",
       " 'n02086646-Blenheim_spaniel': 188,\n",
       " 'n02086910-papillon': 196,\n",
       " 'n02087046-toy_terrier': 166,\n",
       " 'n02087394-Rhodesian_ridgeback': 164,\n",
       " 'n02088094-Afghan_hound': 239,\n",
       " 'n02088238-basset': 168,\n",
       " 'n02088364-beagle': 195,\n",
       " 'n02088466-bloodhound': 187,\n",
       " 'n02088632-bluetick': 158,\n",
       " 'n02089078-black-and-tan_coonhound': 132,\n",
       " 'n02089867-Walker_hound': 82,\n",
       " 'n02089973-English_foxhound': 118,\n",
       " 'n02090379-redbone': 14,\n",
       " 'n02090622-borzoi': 56,\n",
       " 'n02090721-Irish_wolfhound': 218,\n",
       " 'n02091032-Italian_greyhound': 182,\n",
       " 'n02091134-whippet': 187,\n",
       " 'n02091244-Ibizan_hound': 188,\n",
       " 'n02091467-Norwegian_elkhound': 196,\n",
       " 'n02091635-otterhound': 54,\n",
       " 'n02091831-Saluki': 200,\n",
       " 'n02092002-Scottish_deerhound': 232,\n",
       " 'n02092339-Weimaraner': 134,\n",
       " 'n02093256-Staffordshire_bullterrier': 102,\n",
       " 'n02093428-American_Staffordshire_terrier': 140,\n",
       " 'n02093647-Bedlington_terrier': 180,\n",
       " 'n02093754-Border_terrier': 162,\n",
       " 'n02093859-Kerry_blue_terrier': 172,\n",
       " 'n02093991-Irish_terrier': 152,\n",
       " 'n02094114-Norfolk_terrier': 160,\n",
       " 'n02094258-Norwich_terrier': 185,\n",
       " 'n02094433-Yorkshire_terrier': 138,\n",
       " 'n02095314-wire-haired_fox_terrier': 116,\n",
       " 'n02095570-Lakeland_terrier': 197,\n",
       " 'n02095889-Sealyham_terrier': 202,\n",
       " 'n02096051-Airedale': 202,\n",
       " 'n02096177-cairn': 197,\n",
       " 'n02096294-Australian_terrier': 196,\n",
       " 'n02096437-Dandie_Dinmont': 174,\n",
       " 'n02096585-Boston_bull': 178,\n",
       " 'n02097047-miniature_schnauzer': 90,\n",
       " 'n02097130-giant_schnauzer': 114,\n",
       " 'n02097209-standard_schnauzer': 100,\n",
       " 'n02097298-Scotch_terrier': 122,\n",
       " 'n02097474-Tibetan_terrier': 206,\n",
       " 'n02097658-silky_terrier': 183,\n",
       " 'n02098105-soft-coated_wheaten_terrier': 110,\n",
       " 'n02098286-West_Highland_white_terrier': 150,\n",
       " 'n02098413-Lhasa': 186,\n",
       " 'n02099267-flat-coated_retriever': 70,\n",
       " 'n02099429-curly-coated_retriever': 52,\n",
       " 'n02099601-golden_retriever': 42,\n",
       " 'n02099712-Labrador_retriever': 156,\n",
       " 'n02099849-Chesapeake_Bay_retriever': 142,\n",
       " 'n02100236-German_short-haired_pointer': 68,\n",
       " 'n02100583-vizsla': 88,\n",
       " 'n02100735-English_setter': 136,\n",
       " 'n02100877-Irish_setter': 98,\n",
       " 'n02101006-Gordon_setter': 80,\n",
       " 'n02101388-Brittany_spaniel': 66,\n",
       " 'n02101556-clumber': 40,\n",
       " 'n02102040-English_springer': 130,\n",
       " 'n02102177-Welsh_springer_spaniel': 38,\n",
       " 'n02102318-cocker_spaniel': 128,\n",
       " 'n02102480-Sussex_spaniel': 50,\n",
       " 'n02102973-Irish_water_spaniel': 36,\n",
       " 'n02104029-kuvasz': 34,\n",
       " 'n02104365-schipperke': 86,\n",
       " 'n02105056-groenendael': 32,\n",
       " 'n02105162-malinois': 30,\n",
       " 'n02105251-briard': 64,\n",
       " 'n02105412-kelpie': 78,\n",
       " 'n02105505-komondor': 84,\n",
       " 'n02105641-Old_English_sheepdog': 148,\n",
       " 'n02105855-Shetland_sheepdog': 112,\n",
       " 'n02106030-collie': 76,\n",
       " 'n02106166-Border_collie': 28,\n",
       " 'n02106382-Bouvier_des_Flandres': 26,\n",
       " 'n02106550-Rottweiler': 62,\n",
       " 'n02106662-German_shepherd': 60,\n",
       " 'n02107142-Doberman': 24,\n",
       " 'n02107312-miniature_pinscher': 184,\n",
       " 'n02107574-Greater_Swiss_Mountain_dog': 144,\n",
       " 'n02107683-Bernese_mountain_dog': 218,\n",
       " 'n02107908-Appenzeller': 48,\n",
       " 'n02108000-EntleBucher': 202,\n",
       " 'n02108089-boxer': 46,\n",
       " 'n02108422-bull_mastiff': 108,\n",
       " 'n02108551-Tibetan_mastiff': 58,\n",
       " 'n02108915-French_bulldog': 126,\n",
       " 'n02109047-Great_Dane': 106,\n",
       " 'n02109525-Saint_Bernard': 154,\n",
       " 'n02109961-Eskimo_dog': 22,\n",
       " 'n02110063-malamute': 170,\n",
       " 'n02110185-Siberian_husky': 192,\n",
       " 'n02110627-affenpinscher': 20,\n",
       " 'n02110806-basenji': 209,\n",
       " 'n02110958-pug': 200,\n",
       " 'n02111129-Leonberg': 210,\n",
       " 'n02111277-Newfoundland': 195,\n",
       " 'n02111500-Great_Pyrenees': 213,\n",
       " 'n02111889-Samoyed': 218,\n",
       " 'n02112018-Pomeranian': 219,\n",
       " 'n02112137-chow': 196,\n",
       " 'n02112350-keeshond': 120,\n",
       " 'n02112706-Brabancon_griffon': 74,\n",
       " 'n02113023-Pembroke': 176,\n",
       " 'n02113186-Cardigan': 96,\n",
       " 'n02113624-toy_poodle': 44,\n",
       " 'n02113712-miniature_poodle': 94,\n",
       " 'n02113799-standard_poodle': 124,\n",
       " 'n02113978-Mexican_hairless': 92,\n",
       " 'n02115641-dingo': 104,\n",
       " 'n02115913-dhole': 18,\n",
       " 'n02116738-African_hunting_dog': 146}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=0\n",
    "cls_dic={}\n",
    "for i in z:\n",
    "    cls_dic[i]=y[m]\n",
    "    m+=1\n",
    "cls_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sorting the files in the descending order of the number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort={k: v for k, v in sorted(cls_dic.items(), key=lambda item: item[1],reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n02085936-Maltese_dog',\n",
       " 'n02088094-Afghan_hound',\n",
       " 'n02092002-Scottish_deerhound',\n",
       " 'n02112018-Pomeranian',\n",
       " 'n02090721-Irish_wolfhound',\n",
       " 'n02107683-Bernese_mountain_dog',\n",
       " 'n02111889-Samoyed',\n",
       " 'n02086240-Shih-Tzu',\n",
       " 'n02111500-Great_Pyrenees',\n",
       " 'n02111129-Leonberg',\n",
       " 'n02110806-basenji',\n",
       " 'n02097474-Tibetan_terrier',\n",
       " 'n02095889-Sealyham_terrier',\n",
       " 'n02096051-Airedale',\n",
       " 'n02108000-EntleBucher',\n",
       " 'n02091831-Saluki',\n",
       " 'n02110958-pug',\n",
       " 'n02095570-Lakeland_terrier',\n",
       " 'n02096177-cairn',\n",
       " 'n02086910-papillon',\n",
       " 'n02091467-Norwegian_elkhound',\n",
       " 'n02096294-Australian_terrier',\n",
       " 'n02112137-chow',\n",
       " 'n02088364-beagle',\n",
       " 'n02111277-Newfoundland',\n",
       " 'n02110185-Siberian_husky',\n",
       " 'n02086646-Blenheim_spaniel',\n",
       " 'n02091244-Ibizan_hound',\n",
       " 'n02088466-bloodhound',\n",
       " 'n02091134-whippet',\n",
       " 'n02098413-Lhasa',\n",
       " 'n02085782-Japanese_spaniel',\n",
       " 'n02094258-Norwich_terrier',\n",
       " 'n02107312-miniature_pinscher',\n",
       " 'n02097658-silky_terrier',\n",
       " 'n02091032-Italian_greyhound',\n",
       " 'n02093647-Bedlington_terrier',\n",
       " 'n02096585-Boston_bull',\n",
       " 'n02113023-Pembroke',\n",
       " 'n02096437-Dandie_Dinmont',\n",
       " 'n02093859-Kerry_blue_terrier',\n",
       " 'n02110063-malamute',\n",
       " 'n02088238-basset',\n",
       " 'n02087046-toy_terrier',\n",
       " 'n02087394-Rhodesian_ridgeback',\n",
       " 'n02093754-Border_terrier',\n",
       " 'n02094114-Norfolk_terrier',\n",
       " 'n02088632-bluetick',\n",
       " 'n02099712-Labrador_retriever',\n",
       " 'n02109525-Saint_Bernard',\n",
       " 'n02093991-Irish_terrier',\n",
       " 'n02098286-West_Highland_white_terrier',\n",
       " 'n02105641-Old_English_sheepdog',\n",
       " 'n02116738-African_hunting_dog',\n",
       " 'n02107574-Greater_Swiss_Mountain_dog',\n",
       " 'n02099849-Chesapeake_Bay_retriever',\n",
       " 'n02093428-American_Staffordshire_terrier',\n",
       " 'n02094433-Yorkshire_terrier',\n",
       " 'n02100735-English_setter',\n",
       " 'n02092339-Weimaraner',\n",
       " 'n02089078-black-and-tan_coonhound',\n",
       " 'n02102040-English_springer',\n",
       " 'n02102318-cocker_spaniel',\n",
       " 'n02108915-French_bulldog',\n",
       " 'n02113799-standard_poodle',\n",
       " 'n02097298-Scotch_terrier',\n",
       " 'n02112350-keeshond',\n",
       " 'n02089973-English_foxhound',\n",
       " 'n02095314-wire-haired_fox_terrier',\n",
       " 'n02097130-giant_schnauzer',\n",
       " 'n02105855-Shetland_sheepdog',\n",
       " 'n02098105-soft-coated_wheaten_terrier',\n",
       " 'n02108422-bull_mastiff',\n",
       " 'n02109047-Great_Dane',\n",
       " 'n02115641-dingo',\n",
       " 'n02093256-Staffordshire_bullterrier',\n",
       " 'n02097209-standard_schnauzer',\n",
       " 'n02100877-Irish_setter',\n",
       " 'n02113186-Cardigan',\n",
       " 'n02113712-miniature_poodle',\n",
       " 'n02113978-Mexican_hairless',\n",
       " 'n02097047-miniature_schnauzer',\n",
       " 'n02100583-vizsla',\n",
       " 'n02104365-schipperke',\n",
       " 'n02105505-komondor',\n",
       " 'n02089867-Walker_hound',\n",
       " 'n02101006-Gordon_setter',\n",
       " 'n02105412-kelpie',\n",
       " 'n02106030-collie',\n",
       " 'n02112706-Brabancon_griffon',\n",
       " 'n02085620-Chihuahua',\n",
       " 'n02099267-flat-coated_retriever',\n",
       " 'n02100236-German_short-haired_pointer',\n",
       " 'n02101388-Brittany_spaniel',\n",
       " 'n02105251-briard',\n",
       " 'n02106550-Rottweiler',\n",
       " 'n02106662-German_shepherd',\n",
       " 'n02108551-Tibetan_mastiff',\n",
       " 'n02090622-borzoi',\n",
       " 'n02091635-otterhound',\n",
       " 'n02099429-curly-coated_retriever',\n",
       " 'n02102480-Sussex_spaniel',\n",
       " 'n02107908-Appenzeller',\n",
       " 'n02108089-boxer',\n",
       " 'n02113624-toy_poodle',\n",
       " 'n02099601-golden_retriever',\n",
       " 'n02101556-clumber',\n",
       " 'n02102177-Welsh_springer_spaniel',\n",
       " 'n02102973-Irish_water_spaniel',\n",
       " 'n02104029-kuvasz',\n",
       " 'n02105056-groenendael',\n",
       " 'n02105162-malinois',\n",
       " 'n02106166-Border_collie',\n",
       " 'n02106382-Bouvier_des_Flandres',\n",
       " 'n02107142-Doberman',\n",
       " 'n02109961-Eskimo_dog',\n",
       " 'n02110627-affenpinscher',\n",
       " 'n02115913-dhole',\n",
       " 'n02086079-Pekinese',\n",
       " 'n02090379-redbone']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_key=list(sort.keys())\n",
    "sort_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms and Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(    \n",
    "    [transforms.RandomResizedCrop(224),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.438, 0.438, 0.438), (0.237,0.237,0.237))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='./newimages',transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining all the target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = torch.tensor(trainset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0,   0,  ..., 119, 119, 119])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15417"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117,\n",
       "        117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117,\n",
       "        117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117,\n",
       "        117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 118, 118, 118,\n",
       "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list[15200:15270]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = [i for i in y]\n",
    "class_weight = 1./torch.tensor(class_counts, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72,\n",
       " 185,\n",
       " 252,\n",
       " 16,\n",
       " 214,\n",
       " 188,\n",
       " 196,\n",
       " 166,\n",
       " 164,\n",
       " 239,\n",
       " 168,\n",
       " 195,\n",
       " 187,\n",
       " 158,\n",
       " 132,\n",
       " 82,\n",
       " 118,\n",
       " 14,\n",
       " 56,\n",
       " 218,\n",
       " 182,\n",
       " 187,\n",
       " 188,\n",
       " 196,\n",
       " 54,\n",
       " 200,\n",
       " 232,\n",
       " 134,\n",
       " 102,\n",
       " 140,\n",
       " 180,\n",
       " 162,\n",
       " 172,\n",
       " 152,\n",
       " 160,\n",
       " 185,\n",
       " 138,\n",
       " 116,\n",
       " 197,\n",
       " 202,\n",
       " 202,\n",
       " 197,\n",
       " 196,\n",
       " 174,\n",
       " 178,\n",
       " 90,\n",
       " 114,\n",
       " 100,\n",
       " 122,\n",
       " 206,\n",
       " 183,\n",
       " 110,\n",
       " 150,\n",
       " 186,\n",
       " 70,\n",
       " 52,\n",
       " 42,\n",
       " 156,\n",
       " 142,\n",
       " 68,\n",
       " 88,\n",
       " 136,\n",
       " 98,\n",
       " 80,\n",
       " 66,\n",
       " 40,\n",
       " 130,\n",
       " 38,\n",
       " 128,\n",
       " 50,\n",
       " 36,\n",
       " 34,\n",
       " 86,\n",
       " 32,\n",
       " 30,\n",
       " 64,\n",
       " 78,\n",
       " 84,\n",
       " 148,\n",
       " 112,\n",
       " 76,\n",
       " 28,\n",
       " 26,\n",
       " 62,\n",
       " 60,\n",
       " 24,\n",
       " 184,\n",
       " 144,\n",
       " 218,\n",
       " 48,\n",
       " 202,\n",
       " 46,\n",
       " 108,\n",
       " 58,\n",
       " 126,\n",
       " 106,\n",
       " 154,\n",
       " 22,\n",
       " 170,\n",
       " 192,\n",
       " 20,\n",
       " 209,\n",
       " 200,\n",
       " 210,\n",
       " 195,\n",
       " 213,\n",
       " 218,\n",
       " 219,\n",
       " 196,\n",
       " 120,\n",
       " 74,\n",
       " 176,\n",
       " 96,\n",
       " 44,\n",
       " 94,\n",
       " 124,\n",
       " 92,\n",
       " 104,\n",
       " 18,\n",
       " 146]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### obtaining the class weights for the weighted random sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0139, 0.0054, 0.0040, 0.0625, 0.0047, 0.0053, 0.0051, 0.0060, 0.0061,\n",
       "        0.0042, 0.0060, 0.0051, 0.0053, 0.0063, 0.0076, 0.0122, 0.0085, 0.0714,\n",
       "        0.0179, 0.0046, 0.0055, 0.0053, 0.0053, 0.0051, 0.0185, 0.0050, 0.0043,\n",
       "        0.0075, 0.0098, 0.0071, 0.0056, 0.0062, 0.0058, 0.0066, 0.0063, 0.0054,\n",
       "        0.0072, 0.0086, 0.0051, 0.0050, 0.0050, 0.0051, 0.0051, 0.0057, 0.0056,\n",
       "        0.0111, 0.0088, 0.0100, 0.0082, 0.0049, 0.0055, 0.0091, 0.0067, 0.0054,\n",
       "        0.0143, 0.0192, 0.0238, 0.0064, 0.0070, 0.0147, 0.0114, 0.0074, 0.0102,\n",
       "        0.0125, 0.0152, 0.0250, 0.0077, 0.0263, 0.0078, 0.0200, 0.0278, 0.0294,\n",
       "        0.0116, 0.0312, 0.0333, 0.0156, 0.0128, 0.0119, 0.0068, 0.0089, 0.0132,\n",
       "        0.0357, 0.0385, 0.0161, 0.0167, 0.0417, 0.0054, 0.0069, 0.0046, 0.0208,\n",
       "        0.0050, 0.0217, 0.0093, 0.0172, 0.0079, 0.0094, 0.0065, 0.0455, 0.0059,\n",
       "        0.0052, 0.0500, 0.0048, 0.0050, 0.0048, 0.0051, 0.0047, 0.0046, 0.0046,\n",
       "        0.0051, 0.0083, 0.0135, 0.0057, 0.0104, 0.0227, 0.0106, 0.0081, 0.0109,\n",
       "        0.0096, 0.0556, 0.0068])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count = [i for i in y]\n",
    "class_weights = 1./torch.tensor(class_count, dtype=torch.float) \n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4956)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### obtaining weights for each target sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0139, 0.0139, 0.0139,  ..., 0.0068, 0.0068, 0.0068])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights_all = class_weights[target_list]\n",
    "class_weights_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using the pytorch Weighted random sampler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_sampler = WeightedRandomSampler(\n",
    "    weights=class_weights_all,\n",
    "    num_samples=len(class_weights_all),\n",
    "    replacement=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uploading data with pytorch data loader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, sampler=weighted_sampler)\n",
    "\n",
    "classes = tuple(sort_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting default device as GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### downloading pytorch pretrained RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a fully connected layer with 120 neurons \n",
    "#### Uploading model to GPU\n",
    "#### Setting optimizer as Adagrad with learning rate 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.fc = nn.Linear(num_ftrs, 120)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adagrad(model_ft.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading data to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "inputs, labels = data[0].to(device), data[1].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 5.000\n",
      "[1,   400] loss: 4.797\n",
      "[1,   600] loss: 4.803\n",
      "[1,   800] loss: 4.801\n",
      "[1,  1000] loss: 4.798\n",
      "[1,  1200] loss: 4.788\n",
      "[1,  1400] loss: 4.787\n",
      "[1,  1600] loss: 4.780\n",
      "[1,  1800] loss: 4.784\n",
      "[1,  2000] loss: 4.769\n",
      "[1,  2200] loss: 4.766\n",
      "[1,  2400] loss: 4.755\n",
      "[1,  2600] loss: 4.762\n",
      "[1,  2800] loss: 4.760\n",
      "[1,  3000] loss: 4.756\n",
      "[1,  3200] loss: 4.727\n",
      "[1,  3400] loss: 4.719\n",
      "[1,  3600] loss: 4.722\n",
      "[1,  3800] loss: 4.775\n",
      "[2,   200] loss: 4.754\n",
      "[2,   400] loss: 4.756\n",
      "[2,   600] loss: 4.761\n",
      "[2,   800] loss: 4.740\n",
      "[2,  1000] loss: 4.741\n",
      "[2,  1200] loss: 4.770\n",
      "[2,  1400] loss: 4.754\n",
      "[2,  1600] loss: 4.732\n",
      "[2,  1800] loss: 4.730\n",
      "[2,  2000] loss: 4.730\n",
      "[2,  2200] loss: 4.743\n",
      "[2,  2400] loss: 4.717\n",
      "[2,  2600] loss: 4.718\n",
      "[2,  2800] loss: 4.716\n",
      "[2,  3000] loss: 4.727\n",
      "[2,  3200] loss: 4.677\n",
      "[2,  3400] loss: 4.713\n",
      "[2,  3600] loss: 4.705\n",
      "[2,  3800] loss: 4.710\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model_ft(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving model as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trans_learn_Model.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(model_ft, 'trans_learn_Model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (23): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (24): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (25): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (26): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (27): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (28): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (29): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (30): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (31): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (32): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (33): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (34): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (35): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=120, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
